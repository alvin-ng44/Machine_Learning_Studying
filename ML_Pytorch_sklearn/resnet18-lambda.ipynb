{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377dc768-6e18-444c-bcc8-741eb27b20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, SequentialLR, LambdaLR\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6461f4fa-326a-4ca1-a108-e1e4e08c4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_data = '/mnt/d/Users/Admin/Projects/Machine_Learning/data'\n",
    "delta_data = '/workspace/alvin/Machine_Learning_Studying/data'\n",
    "data_lst = [lambda_data, delta_data]\n",
    "data_pth = data_lst[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09fdeca5-901b-45ee-8be8-366ace8e3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\" : transforms.Compose([\n",
    "        transforms.Resize(size = (224, 224)), # resize to 224 by 224 for resnet\n",
    "        # transforms.CenterCrop(size = (224, 224)),\n",
    "        transforms.Grayscale(num_output_channels = 3), # this converts grayscale to rgb channels\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"test\" : transforms.Compose([\n",
    "        transforms.Resize(size = (224, 224)), # resize to 224 by 224 for resnet\n",
    "        # transforms.CenterCrop(size = (224, 224)),\n",
    "        transforms.Grayscale(num_output_channels = 3), # this converts grayscale to rgb channels\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413fd109-c338-4fe5-a5b7-2cc173ea884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4756577-edc5-4cf1-ae45-4520d7bc5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root = data_pth,\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = data_transforms[\"train\"]\n",
    ")\n",
    "\n",
    "train_ds, val_ds = random_split(training_data, [50_000, 10_000])\n",
    "\n",
    "ds_dict = {\"train\" : train_ds, \"val\" : val_ds}\n",
    "dataset_sizes = {\"train\" : len(train_ds), \"val\" : len(val_ds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ab5a2c-2c4b-4c1d-ae80-001e412ad483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /mnt/d/Users/Admin/Projects/Machine_Learning/data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               Grayscale(num_output_channels=3)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f5f6972-1858-4b9e-9445-d7b67082a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x : DataLoader(ds_dict[x], batch_size = 2**9, num_workers = 4, shuffle = True) for x in ds_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596a9297-ca6d-4a32-bb20-53869aeb0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "model = models.resnet18(weights = \"DEFAULT\")\n",
    "# Replace final layer for the number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labels_map))\n",
    "\n",
    "# Freeze all layers except final layer\n",
    "# final layer is responsible for classification\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" in name:\n",
    "        # unfreeze the fc layers\n",
    "        # this means we are only training the fc layers\n",
    "        param.requires_grad = True \n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # most common used nn for classification problems\n",
    "# optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "# scheduler = StepLR(optimizer, step_size = 10, gamma = 0.1) # this multiplies lr every 10 epoch by 0.1\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)\n",
    "\n",
    "def warmup_lambda(epoch):\n",
    "    if epoch < 20:\n",
    "        # scale from 0.5 (0.1/0.2) up to 1.0\n",
    "        return 0.5 + (epoch / 20) * 0.5\n",
    "    return 1.0\n",
    "\n",
    "scheduler1 = LambdaLR(optimizer, lr_lambda = warmup_lambda)\n",
    "scheduler2 = StepLR(optimizer, step_size = 4, gamma = 0.5)\n",
    "scheduler = SequentialLR(optimizer, schedulers = [scheduler1, scheduler2], milestones = [20])\n",
    "\n",
    "# move model to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cae5e4c-c4ff-4f17-b431-e7482610c8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "train Loss: 0.8780 Acc: 0.7339\n",
      "val Loss: 0.6273 Acc: 0.7929\n",
      "Epoch 1 LR: 0.0525000000\n",
      "Epoch 1\n",
      "train Loss: 0.5413 Acc: 0.8216\n",
      "val Loss: 0.5305 Acc: 0.8180\n",
      "Epoch 2 LR: 0.0550000000\n",
      "Epoch 2\n",
      "train Loss: 0.4863 Acc: 0.8356\n",
      "val Loss: 0.4980 Acc: 0.8271\n",
      "Epoch 3 LR: 0.0575000000\n",
      "Epoch 3\n",
      "train Loss: 0.4583 Acc: 0.8436\n",
      "val Loss: 0.4979 Acc: 0.8261\n",
      "Epoch 4 LR: 0.0600000000\n",
      "Epoch 4\n",
      "train Loss: 0.4434 Acc: 0.8458\n",
      "val Loss: 0.4454 Acc: 0.8442\n",
      "Epoch 5 LR: 0.0625000000\n",
      "Epoch 5\n",
      "train Loss: 0.4267 Acc: 0.8514\n",
      "val Loss: 0.4550 Acc: 0.8374\n",
      "Epoch 6 LR: 0.0650000000\n",
      "Epoch 6\n",
      "train Loss: 0.4200 Acc: 0.8532\n",
      "val Loss: 0.4288 Acc: 0.8474\n",
      "Epoch 7 LR: 0.0675000000\n",
      "Epoch 7\n",
      "train Loss: 0.4134 Acc: 0.8536\n",
      "val Loss: 0.4218 Acc: 0.8517\n",
      "Epoch 8 LR: 0.0700000000\n",
      "Epoch 8\n",
      "train Loss: 0.4065 Acc: 0.8557\n",
      "val Loss: 0.4315 Acc: 0.8456\n",
      "Epoch 9 LR: 0.0725000000\n",
      "Epoch 9\n",
      "train Loss: 0.3988 Acc: 0.8591\n",
      "val Loss: 0.4273 Acc: 0.8472\n",
      "Epoch 10 LR: 0.0750000000\n",
      "Epoch 10\n",
      "train Loss: 0.3919 Acc: 0.8601\n",
      "val Loss: 0.4229 Acc: 0.8481\n",
      "Epoch 11 LR: 0.0775000000\n",
      "Epoch 11\n",
      "train Loss: 0.3848 Acc: 0.8646\n",
      "val Loss: 0.4131 Acc: 0.8547\n",
      "Epoch 12 LR: 0.0800000000\n",
      "Epoch 12\n",
      "train Loss: 0.3890 Acc: 0.8607\n",
      "val Loss: 0.4047 Acc: 0.8565\n",
      "Epoch 13 LR: 0.0825000000\n",
      "Epoch 13\n",
      "train Loss: 0.3870 Acc: 0.8616\n",
      "val Loss: 0.3974 Acc: 0.8572\n",
      "Epoch 14 LR: 0.0850000000\n",
      "Epoch 14\n",
      "train Loss: 0.3842 Acc: 0.8620\n",
      "val Loss: 0.4194 Acc: 0.8507\n",
      "Epoch 15 LR: 0.0875000000\n",
      "Epoch 15\n",
      "train Loss: 0.4066 Acc: 0.8568\n",
      "val Loss: 0.4261 Acc: 0.8483\n",
      "Epoch 16 LR: 0.0900000000\n",
      "Epoch 16\n",
      "train Loss: 0.3897 Acc: 0.8615\n",
      "val Loss: 0.4000 Acc: 0.8567\n",
      "Epoch 17 LR: 0.0925000000\n",
      "Epoch 17\n",
      "train Loss: 0.3862 Acc: 0.8635\n",
      "val Loss: 0.4124 Acc: 0.8548\n",
      "Epoch 18 LR: 0.0950000000\n",
      "Epoch 18\n",
      "train Loss: 0.3993 Acc: 0.8585\n",
      "val Loss: 0.4584 Acc: 0.8390\n",
      "Epoch 19 LR: 0.0975000000\n",
      "Epoch 19\n",
      "train Loss: 0.4086 Acc: 0.8566\n",
      "val Loss: 0.4023 Acc: 0.8582\n",
      "Epoch 20 LR: 0.1000000000\n",
      "Epoch 20\n",
      "train Loss: 0.3979 Acc: 0.8600\n",
      "val Loss: 0.4084 Acc: 0.8557\n",
      "Epoch 21 LR: 0.1000000000\n",
      "Epoch 21\n",
      "train Loss: 0.3840 Acc: 0.8631\n",
      "val Loss: 0.4325 Acc: 0.8470\n",
      "Epoch 22 LR: 0.1000000000\n",
      "Epoch 22\n",
      "train Loss: 0.3918 Acc: 0.8625\n",
      "val Loss: 0.4194 Acc: 0.8539\n",
      "Epoch 23 LR: 0.1000000000\n",
      "Epoch 23\n",
      "train Loss: 0.3852 Acc: 0.8643\n",
      "val Loss: 0.4055 Acc: 0.8573\n",
      "Epoch 24 LR: 0.0500000000\n",
      "Epoch 24\n",
      "train Loss: 0.3428 Acc: 0.8771\n",
      "val Loss: 0.3805 Acc: 0.8630\n",
      "Epoch 25 LR: 0.0500000000\n",
      "Epoch 25\n",
      "train Loss: 0.3406 Acc: 0.8778\n",
      "val Loss: 0.3779 Acc: 0.8636\n",
      "Epoch 26 LR: 0.0500000000\n",
      "Epoch 26\n",
      "train Loss: 0.3399 Acc: 0.8783\n",
      "val Loss: 0.3804 Acc: 0.8622\n",
      "Epoch 27 LR: 0.0500000000\n",
      "Epoch 27\n",
      "train Loss: 0.3383 Acc: 0.8791\n",
      "val Loss: 0.3777 Acc: 0.8656\n",
      "Epoch 28 LR: 0.0250000000\n",
      "Epoch 28\n",
      "train Loss: 0.3355 Acc: 0.8798\n",
      "val Loss: 0.3776 Acc: 0.8638\n",
      "Epoch 29 LR: 0.0250000000\n",
      "Epoch 29\n",
      "train Loss: 0.3342 Acc: 0.8812\n",
      "val Loss: 0.3758 Acc: 0.8653\n",
      "Epoch 30 LR: 0.0250000000\n",
      "Epoch 30\n",
      "train Loss: 0.3349 Acc: 0.8805\n",
      "val Loss: 0.3760 Acc: 0.8644\n",
      "Epoch 31 LR: 0.0250000000\n",
      "Epoch 31\n",
      "train Loss: 0.3339 Acc: 0.8813\n",
      "val Loss: 0.3759 Acc: 0.8651\n",
      "Epoch 32 LR: 0.0125000000\n",
      "Epoch 32\n",
      "train Loss: 0.3333 Acc: 0.8809\n",
      "val Loss: 0.3749 Acc: 0.8641\n",
      "Epoch 33 LR: 0.0125000000\n",
      "Epoch 33\n",
      "train Loss: 0.3333 Acc: 0.8813\n",
      "val Loss: 0.3747 Acc: 0.8650\n",
      "Epoch 34 LR: 0.0125000000\n",
      "Epoch 34\n",
      "train Loss: 0.3323 Acc: 0.8813\n",
      "val Loss: 0.3745 Acc: 0.8645\n",
      "Epoch 35 LR: 0.0125000000\n",
      "Epoch 35\n",
      "train Loss: 0.3328 Acc: 0.8818\n",
      "val Loss: 0.3744 Acc: 0.8641\n",
      "Epoch 36 LR: 0.0062500000\n",
      "Epoch 36\n",
      "train Loss: 0.3316 Acc: 0.8812\n",
      "val Loss: 0.3741 Acc: 0.8646\n",
      "Epoch 37 LR: 0.0062500000\n",
      "Epoch 37\n",
      "train Loss: 0.3312 Acc: 0.8820\n",
      "val Loss: 0.3742 Acc: 0.8643\n",
      "Epoch 38 LR: 0.0062500000\n",
      "Epoch 38\n",
      "train Loss: 0.3314 Acc: 0.8816\n",
      "val Loss: 0.3743 Acc: 0.8655\n",
      "Epoch 39 LR: 0.0062500000\n",
      "Epoch 39\n",
      "train Loss: 0.3317 Acc: 0.8815\n",
      "val Loss: 0.3743 Acc: 0.8644\n",
      "Epoch 40 LR: 0.0031250000\n",
      "Epoch 40\n",
      "train Loss: 0.3314 Acc: 0.8817\n",
      "val Loss: 0.3742 Acc: 0.8646\n",
      "Epoch 41 LR: 0.0031250000\n",
      "Epoch 41\n",
      "train Loss: 0.3311 Acc: 0.8822\n",
      "val Loss: 0.3741 Acc: 0.8651\n",
      "Epoch 42 LR: 0.0031250000\n",
      "Epoch 42\n",
      "train Loss: 0.3311 Acc: 0.8815\n",
      "val Loss: 0.3740 Acc: 0.8647\n",
      "Epoch 43 LR: 0.0031250000\n",
      "Epoch 43\n",
      "train Loss: 0.3311 Acc: 0.8822\n",
      "val Loss: 0.3739 Acc: 0.8650\n",
      "Epoch 44 LR: 0.0015625000\n",
      "Epoch 44\n",
      "train Loss: 0.3305 Acc: 0.8828\n",
      "val Loss: 0.3745 Acc: 0.8635\n",
      "Epoch 45 LR: 0.0015625000\n",
      "Epoch 45\n",
      "train Loss: 0.3307 Acc: 0.8821\n",
      "val Loss: 0.3734 Acc: 0.8642\n",
      "Epoch 46 LR: 0.0015625000\n",
      "Epoch 46\n",
      "train Loss: 0.3312 Acc: 0.8815\n",
      "val Loss: 0.3736 Acc: 0.8651\n",
      "Epoch 47 LR: 0.0015625000\n",
      "Epoch 47\n",
      "train Loss: 0.3310 Acc: 0.8822\n",
      "val Loss: 0.3738 Acc: 0.8640\n",
      "Epoch 48 LR: 0.0007812500\n",
      "Epoch 48\n",
      "train Loss: 0.3309 Acc: 0.8818\n",
      "val Loss: 0.3742 Acc: 0.8652\n",
      "Epoch 49 LR: 0.0007812500\n",
      "Epoch 49\n",
      "train Loss: 0.3304 Acc: 0.8818\n",
      "val Loss: 0.3740 Acc: 0.8650\n",
      "Epoch 50 LR: 0.0007812500\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Training loops\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0 # correct predictions\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # clear the gradient from previous iteration\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels) # check if output and labels match\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1} LR: {scheduler.get_last_lr()[0]:.10f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833108fa-fd0a-4dbf-9eb4-ca7fd56e24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), \"/mnt/d/Users/Admin/Projects/Machine_Learning/weights/fashionmnist_epoch_50_resnet18_adaptive_lambda.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbddf23-3c6c-49ec-a103-a1656088e626",
   "metadata": {},
   "source": [
    "## Classification on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da579d28-efa0-4b55-b2ce-84ddde45ddf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = models.resnet18(weights = None) # dont load ImageNet Weights\n",
    "new_model.fc = nn.Linear(new_model.fc.in_features, len(labels_map))\n",
    "\n",
    "# Load your trained weights\n",
    "new_model.load_state_dict(torch.load(\n",
    "    \"/mnt/d/Users/Admin/Projects/Machine_Learning/weights/fashionmnist_epoch_50_resnet18_adaptive_lambda.pth\",\n",
    "    map_location=device\n",
    "))\n",
    "\n",
    "new_model = new_model.to(device)\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43be0237-2be2-4d6c-8e5d-d658fdc5513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root = data_pth,\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = data_transforms[\"test\"]\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size = 128,\n",
    "    num_workers = 8,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61261f8c-254d-4d6c-80a6-fcb8c77b574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8669\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = new_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        correct += torch.sum(preds == labels).item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec9dbc2-9a2b-4f3a-b1a3-6756b9749379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1 \n",
      " Pred: Ankle Boot, True: Ankle Boot\n",
      "image 2 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 3 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 4 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 5 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 6 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 7 \n",
      " Pred: Coat, True: Coat\n",
      "image 8 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 9 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 10 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 11 \n",
      " Pred: Coat, True: Coat\n",
      "image 12 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 13 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 14 \n",
      " Pred: Dress, True: Dress\n",
      "image 15 \n",
      " Pred: Coat, True: Coat\n",
      "image 16 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 17 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 18 \n",
      " Pred: T-Shirt, True: Coat\n",
      "image 19 \n",
      " Pred: Bag, True: Bag\n",
      "image 20 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 21 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 22 \n",
      " Pred: Sneaker, True: Sandal\n",
      "image 23 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 24 \n",
      " Pred: Sandal, True: Ankle Boot\n",
      "image 25 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 26 \n",
      " Pred: Shirt, True: Coat\n",
      "image 27 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 28 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 29 \n",
      " Pred: Ankle Boot, True: Ankle Boot\n",
      "image 30 \n",
      " Pred: Shirt, True: Dress\n",
      "image 31 \n",
      " Pred: Bag, True: Bag\n",
      "image 32 \n",
      " Pred: Bag, True: Bag\n",
      "image 33 \n",
      " Pred: Dress, True: Dress\n",
      "image 34 \n",
      " Pred: Dress, True: Dress\n",
      "image 35 \n",
      " Pred: Bag, True: Bag\n",
      "image 36 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 37 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 38 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 39 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 40 \n",
      " Pred: Ankle Boot, True: Ankle Boot\n",
      "image 41 \n",
      " Pred: T-Shirt, True: Shirt\n",
      "image 42 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 43 \n",
      " Pred: Dress, True: Dress\n",
      "image 44 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 45 \n",
      " Pred: Coat, True: Shirt\n",
      "image 46 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 47 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 48 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 49 \n",
      " Pred: Coat, True: Pullover\n",
      "image 50 \n",
      " Pred: Shirt, True: Pullover\n",
      "image 51 \n",
      " Pred: Coat, True: Coat\n",
      "image 52 \n",
      " Pred: Coat, True: Coat\n",
      "image 53 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 54 \n",
      " Pred: Bag, True: Bag\n",
      "image 55 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 56 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 57 \n",
      " Pred: Bag, True: Bag\n",
      "image 58 \n",
      " Pred: Coat, True: Coat\n",
      "image 59 \n",
      " Pred: Bag, True: Bag\n",
      "image 60 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 61 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 62 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 63 \n",
      " Pred: Bag, True: Bag\n",
      "image 64 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 65 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 66 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 67 \n",
      " Pred: Coat, True: Pullover\n",
      "image 68 \n",
      " Pred: Dress, True: Dress\n",
      "image 69 \n",
      " Pred: Sneaker, True: Ankle Boot\n",
      "image 70 \n",
      " Pred: Bag, True: Bag\n",
      "image 71 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 72 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 73 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 74 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 75 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 76 \n",
      " Pred: Dress, True: Dress\n",
      "image 77 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 78 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 79 \n",
      " Pred: Bag, True: Bag\n",
      "image 80 \n",
      " Pred: Coat, True: Coat\n",
      "image 81 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 82 \n",
      " Pred: Bag, True: Bag\n",
      "image 83 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 84 \n",
      " Pred: Ankle Boot, True: Ankle Boot\n",
      "image 85 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 86 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 87 \n",
      " Pred: Dress, True: Dress\n",
      "image 88 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 89 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 90 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 91 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 92 \n",
      " Pred: Dress, True: Dress\n",
      "image 93 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 94 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 95 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 96 \n",
      " Pred: Bag, True: Bag\n",
      "image 97 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 98 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 99 \n",
      " Pred: Pullover, True: Coat\n",
      "image 100 \n",
      " Pred: Pullover, True: Pullover\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    image, label = test_data[i]\n",
    "    image_batch = image.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = new_model(image_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    pred_class = preds.item()\n",
    "    \n",
    "    # plt.imshow(image[0].squeeze(), cmap = \"gray\")\n",
    "    # plt.title(f\"image {i+1}\")\n",
    "    print(f\"image {i+1} \\n Pred: {labels_map[pred_class]}, True: {labels_map[label]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612c4f3-3c15-407e-bece-e3a302566a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
