{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "377dc768-6e18-444c-bcc8-741eb27b20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, SequentialLR, LambdaLR, OneCycleLR\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6461f4fa-326a-4ca1-a108-e1e4e08c4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_data = '/mnt/d/Users/Admin/Projects/Machine_Learning/data'\n",
    "delta_data = '/workspace/alvin/Machine_Learning_Studying/data'\n",
    "data_lst = [lambda_data, delta_data]\n",
    "data_pth = data_lst[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09fdeca5-901b-45ee-8be8-366ace8e3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\" : transforms.Compose([\n",
    "        transforms.Resize(size = (224, 224)), # resize to 224 by 224 for resnet\n",
    "        # transforms.CenterCrop(size = (224, 224)),\n",
    "        transforms.Grayscale(num_output_channels = 3), # this converts grayscale to rgb channels\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \"test\" : transforms.Compose([\n",
    "        transforms.Resize(size = (224, 224)), # resize to 224 by 224 for resnet\n",
    "        # transforms.CenterCrop(size = (224, 224)),\n",
    "        transforms.Grayscale(num_output_channels = 3), # this converts grayscale to rgb channels\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413fd109-c338-4fe5-a5b7-2cc173ea884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4756577-edc5-4cf1-ae45-4520d7bc5ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root = data_pth,\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = data_transforms[\"train\"]\n",
    ")\n",
    "\n",
    "train_ds, val_ds = random_split(training_data, [50_000, 10_000])\n",
    "\n",
    "ds_dict = {\"train\" : train_ds, \"val\" : val_ds}\n",
    "dataset_sizes = {\"train\" : len(train_ds), \"val\" : len(val_ds)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49ab5a2c-2c4b-4c1d-ae80-001e412ad483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /workspace/alvin/Machine_Learning_Studying/data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
       "               Grayscale(num_output_channels=3)\n",
       "               ToTensor()\n",
       "               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "           )"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f5f6972-1858-4b9e-9445-d7b67082a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x : DataLoader(ds_dict[x], batch_size = 256, num_workers = 1, shuffle = True) for x in ds_dict.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "596a9297-ca6d-4a32-bb20-53869aeb0f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "model = models.resnet18(weights = \"DEFAULT\")\n",
    "# Replace final layer for the number of classes\n",
    "model.fc = nn.Linear(model.fc.in_features, len(labels_map))\n",
    "\n",
    "# Freeze all layers except final layer\n",
    "# final layer is responsible for classification\n",
    "for name, param in model.named_parameters():\n",
    "    if \"fc\" in name:\n",
    "        # unfreeze the fc layers\n",
    "        # this means we are only training the fc layers\n",
    "        param.requires_grad = True \n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss() # most common used nn for classification problems\n",
    "# optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "# scheduler = StepLR(optimizer, step_size = 10, gamma = 0.1) # this multiplies lr every 10 epoch by 0.1\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n",
    "\n",
    "# def warmup_lambda(epoch):\n",
    "#     if epoch < 20:\n",
    "#         # scale from 0.5 (0.1/0.2) up to 1.0\n",
    "#         return 0.5 + (epoch / 20) * 0.5\n",
    "#     return 1.0\n",
    "\n",
    "# scheduler1 = LambdaLR(optimizer, lr_lambda = warmup_lambda)\n",
    "# scheduler2 = StepLR(optimizer, step_size = 4, gamma = 0.5)\n",
    "# scheduler = SequentialLR(optimizer, schedulers = [scheduler1, scheduler2], milestones = [20])\n",
    "\n",
    "scheduler = OneCycleLR(optimizer, max_lr = 0.0125, epochs = 50, steps_per_epoch = len(dataloaders[\"train\"]))\n",
    "\n",
    "# move model to GPU\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cae5e4c-c4ff-4f17-b431-e7482610c8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m     12\u001b[39m running_corrects = \u001b[32m0\u001b[39m \u001b[38;5;66;03m# correct predictions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mphase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/py_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/py_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1482\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1479\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1481\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1482\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1485\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/py_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1444\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1440\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1441\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1446\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/py_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1275\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1263\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1264\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1274\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1275\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1276\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1277\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1278\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1279\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1280\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:257\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    256\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:440\u001b[39m, in \u001b[36mConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     r = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/multiprocessing/connection.py:1136\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m   1133\u001b[39m     deadline = time.monotonic() + timeout\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[32m   1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m [key.fileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training loops\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    for phase in [\"train\", \"val\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0 # correct predictions\n",
    "\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # clear the gradient from previous iteration\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels) # check if output and labels match\n",
    "\n",
    "                if phase == \"train\":\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    scheduler.step() # scheduler here if OneCycleLR\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    # scheduler.step()\n",
    "    print(f\"Epoch {epoch+1} LR: {scheduler.get_last_lr()[0]:.10f}\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "833108fa-fd0a-4dbf-9eb4-ca7fd56e24df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), \"/mnt/d/Users/Admin/Projects/Machine_Learning/weights/fashionmnist_epoch_50_resnet18_adaptive_lambda.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbddf23-3c6c-49ec-a103-a1656088e626",
   "metadata": {},
   "source": [
    "## Classification on Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da579d28-efa0-4b55-b2ce-84ddde45ddf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = models.resnet18(weights = None) # dont load ImageNet Weights\n",
    "new_model.fc = nn.Linear(new_model.fc.in_features, len(labels_map))\n",
    "\n",
    "# Load your trained weights\n",
    "new_model.load_state_dict(torch.load(\n",
    "    \"/mnt/d/Users/Admin/Projects/Machine_Learning/weights/fashionmnist_epoch_50_resnet18_adaptive_lambda.pth\",\n",
    "    map_location=device\n",
    "))\n",
    "\n",
    "new_model = new_model.to(device)\n",
    "new_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43be0237-2be2-4d6c-8e5d-d658fdc5513d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root = data_pth,\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = data_transforms[\"test\"]\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size = 128,\n",
    "    num_workers = 8,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61261f8c-254d-4d6c-80a6-fcb8c77b574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8669\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = new_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        correct += torch.sum(preds == labels).item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "test_acc = correct / total\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec9dbc2-9a2b-4f3a-b1a3-6756b9749379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1 \n",
      " Pred: Ankle Boot, True: Ankle Boot\n",
      "image 2 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 3 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 4 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 5 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 6 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 7 \n",
      " Pred: Coat, True: Coat\n",
      "image 8 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 9 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 10 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 11 \n",
      " Pred: Coat, True: Coat\n",
      "image 12 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 13 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 14 \n",
      " Pred: Dress, True: Dress\n",
      "image 15 \n",
      " Pred: Coat, True: Coat\n",
      "image 16 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 17 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 18 \n",
      " Pred: T-Shirt, True: Coat\n",
      "image 19 \n",
      " Pred: Bag, True: Bag\n",
      "image 20 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 21 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 22 \n",
      " Pred: Sneaker, True: Sandal\n",
      "image 23 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 24 \n",
      " Pred: Sandal, True: Ankle Boot\n",
      "image 25 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 26 \n",
      " Pred: Shirt, True: Coat\n",
      "image 27 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 28 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 29 \n",
      " Pred: Ankle Boot, True: Ankle Boot\n",
      "image 30 \n",
      " Pred: Shirt, True: Dress\n",
      "image 31 \n",
      " Pred: Bag, True: Bag\n",
      "image 32 \n",
      " Pred: Bag, True: Bag\n",
      "image 33 \n",
      " Pred: Dress, True: Dress\n",
      "image 34 \n",
      " Pred: Dress, True: Dress\n",
      "image 35 \n",
      " Pred: Bag, True: Bag\n",
      "image 36 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 37 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 38 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 39 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 40 \n",
      " Pred: Ankle Boot, True: Ankle Boot\n",
      "image 41 \n",
      " Pred: T-Shirt, True: Shirt\n",
      "image 42 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 43 \n",
      " Pred: Dress, True: Dress\n",
      "image 44 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 45 \n",
      " Pred: Coat, True: Shirt\n",
      "image 46 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 47 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 48 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 49 \n",
      " Pred: Coat, True: Pullover\n",
      "image 50 \n",
      " Pred: Shirt, True: Pullover\n",
      "image 51 \n",
      " Pred: Coat, True: Coat\n",
      "image 52 \n",
      " Pred: Coat, True: Coat\n",
      "image 53 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 54 \n",
      " Pred: Bag, True: Bag\n",
      "image 55 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 56 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 57 \n",
      " Pred: Bag, True: Bag\n",
      "image 58 \n",
      " Pred: Coat, True: Coat\n",
      "image 59 \n",
      " Pred: Bag, True: Bag\n",
      "image 60 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 61 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 62 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 63 \n",
      " Pred: Bag, True: Bag\n",
      "image 64 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 65 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 66 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 67 \n",
      " Pred: Coat, True: Pullover\n",
      "image 68 \n",
      " Pred: Dress, True: Dress\n",
      "image 69 \n",
      " Pred: Sneaker, True: Ankle Boot\n",
      "image 70 \n",
      " Pred: Bag, True: Bag\n",
      "image 71 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 72 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 73 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 74 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 75 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 76 \n",
      " Pred: Dress, True: Dress\n",
      "image 77 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 78 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 79 \n",
      " Pred: Bag, True: Bag\n",
      "image 80 \n",
      " Pred: Coat, True: Coat\n",
      "image 81 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 82 \n",
      " Pred: Bag, True: Bag\n",
      "image 83 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 84 \n",
      " Pred: Ankle Boot, True: Ankle Boot\n",
      "image 85 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 86 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 87 \n",
      " Pred: Dress, True: Dress\n",
      "image 88 \n",
      " Pred: Pullover, True: Pullover\n",
      "image 89 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 90 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 91 \n",
      " Pred: Sandal, True: Sandal\n",
      "image 92 \n",
      " Pred: Dress, True: Dress\n",
      "image 93 \n",
      " Pred: Shirt, True: Shirt\n",
      "image 94 \n",
      " Pred: Sneaker, True: Sneaker\n",
      "image 95 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 96 \n",
      " Pred: Bag, True: Bag\n",
      "image 97 \n",
      " Pred: T-Shirt, True: T-Shirt\n",
      "image 98 \n",
      " Pred: Trouser, True: Trouser\n",
      "image 99 \n",
      " Pred: Pullover, True: Coat\n",
      "image 100 \n",
      " Pred: Pullover, True: Pullover\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    image, label = test_data[i]\n",
    "    image_batch = image.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = new_model(image_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "    pred_class = preds.item()\n",
    "    \n",
    "    # plt.imshow(image[0].squeeze(), cmap = \"gray\")\n",
    "    # plt.title(f\"image {i+1}\")\n",
    "    print(f\"image {i+1} \\n Pred: {labels_map[pred_class]}, True: {labels_map[label]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612c4f3-3c15-407e-bece-e3a302566a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
